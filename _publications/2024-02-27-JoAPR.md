---
title: "JoAPR: Cleaning the Lens of Prompt Learning for Vision-Language Models"
collection: publications
category: conferences
permalink: /publication/2024-02-17-JoAPR
excerpt: 'This article aims to address the issue of label noise in prompt learning for vision-language models.'
date: 2024-02-27
venue: 'CVPR2024'
paperurl: 'https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_JoAPR_Cleaning_the_Lens_of_Prompt_Learning_for_Vision-Language_Models_CVPR_2024_paper.pdf'
codeurl: 'https://github.com/yunncheng/JoAPR'
citation: 'Guo Y, Gu X. JoAPR: Cleaning the Lens of Prompt Learning for Vision-Language Models[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 28695-28705.'
---

Leveraging few-shot datasets in prompt learning for Vision-Language Models eliminates the need for manual prompt engineering while highlighting the necessity of accurate annotations for the labels. However, high-level or complex label noise challenges prompt learning for Vision-Language Models. Aiming at this issue, we propose a new framework for improving its robustness. Specifically, we introduce the Joint Adaptive Partitioning for Label Refurbishment (JoAPR), a structured framework encompassing two key steps. 1) Data Partitioning, where we differentiate between clean and noisy data using joint adaptive thresholds. 2) Label Refurbishment, where we correct the labels based on the partition outcomes before retraining the network. Our comprehensive experiments confirm that JoAPR substantially enhances the robustness of prompt learning for Vision-Language Models against label noise, offering a promising direction for future research.
